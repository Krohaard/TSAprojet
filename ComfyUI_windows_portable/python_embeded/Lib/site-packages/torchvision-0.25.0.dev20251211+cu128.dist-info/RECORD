torchvision-0.25.0.dev20251211+cu128.dist-info/INSTALLER,sha256=zuuue4knoyJ-UwPPXg8fezS7VCrXJQrAP7zeNuwvFQg,4
torchvision-0.25.0.dev20251211+cu128.dist-info/LICENSE,,
torchvision-0.25.0.dev20251211+cu128.dist-info/METADATA,,
torchvision-0.25.0.dev20251211+cu128.dist-info/RECORD,,
torchvision-0.25.0.dev20251211+cu128.dist-info/REQUESTED,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
torchvision-0.25.0.dev20251211+cu128.dist-info/WHEEL,,
torchvision-0.25.0.dev20251211+cu128.dist-info/top_level.txt,,
torchvision-0.25.0.dev20251211+cu128.dist-info\LICENSE,sha256=wGNj-dM2J9xRc7E1IkRMyF-7Rzn2PhbUWH1cChZbWx4,1546
torchvision-0.25.0.dev20251211+cu128.dist-info\METADATA,sha256=xgAYYSnPuW-pxv04i2BajHs_5WyblPaCQooXvNjtuQI,5535
torchvision-0.25.0.dev20251211+cu128.dist-info\RECORD,,
torchvision-0.25.0.dev20251211+cu128.dist-info\WHEEL,sha256=KNRoynpGu-d6mheJI-zfvcGl1iN-y8BewbiCDXsF3cY,101
torchvision-0.25.0.dev20251211+cu128.dist-info\top_level.txt,sha256=ucJZoaluBW9BGYT4TuCE6zoZY_JuSP30wbDh-IRpxUU,12
torchvision/_C.pyd,,
torchvision/__init__.py,,
torchvision/__pycache__/__init__.cpython-312.pyc,,
torchvision/__pycache__/_internally_replaced_utils.cpython-312.pyc,,
torchvision/__pycache__/_meta_registrations.cpython-312.pyc,,
torchvision/__pycache__/_utils.cpython-312.pyc,,
torchvision/__pycache__/extension.cpython-312.pyc,,
torchvision/__pycache__/utils.cpython-312.pyc,,
torchvision/__pycache__/version.cpython-312.pyc,,
torchvision/_internally_replaced_utils.py,,
torchvision/_meta_registrations.py,,
torchvision/_utils.py,,
torchvision/cudart64_12.dll,,
torchvision/datasets/__init__.py,,
torchvision/datasets/__pycache__/__init__.cpython-312.pyc,,
torchvision/datasets/__pycache__/_optical_flow.cpython-312.pyc,,
torchvision/datasets/__pycache__/_stereo_matching.cpython-312.pyc,,
torchvision/datasets/__pycache__/caltech.cpython-312.pyc,,
torchvision/datasets/__pycache__/celeba.cpython-312.pyc,,
torchvision/datasets/__pycache__/cifar.cpython-312.pyc,,
torchvision/datasets/__pycache__/cityscapes.cpython-312.pyc,,
torchvision/datasets/__pycache__/clevr.cpython-312.pyc,,
torchvision/datasets/__pycache__/coco.cpython-312.pyc,,
torchvision/datasets/__pycache__/country211.cpython-312.pyc,,
torchvision/datasets/__pycache__/dtd.cpython-312.pyc,,
torchvision/datasets/__pycache__/eurosat.cpython-312.pyc,,
torchvision/datasets/__pycache__/fakedata.cpython-312.pyc,,
torchvision/datasets/__pycache__/fer2013.cpython-312.pyc,,
torchvision/datasets/__pycache__/fgvc_aircraft.cpython-312.pyc,,
torchvision/datasets/__pycache__/flickr.cpython-312.pyc,,
torchvision/datasets/__pycache__/flowers102.cpython-312.pyc,,
torchvision/datasets/__pycache__/folder.cpython-312.pyc,,
torchvision/datasets/__pycache__/food101.cpython-312.pyc,,
torchvision/datasets/__pycache__/gtsrb.cpython-312.pyc,,
torchvision/datasets/__pycache__/hmdb51.cpython-312.pyc,,
torchvision/datasets/__pycache__/imagenet.cpython-312.pyc,,
torchvision/datasets/__pycache__/imagenette.cpython-312.pyc,,
torchvision/datasets/__pycache__/inaturalist.cpython-312.pyc,,
torchvision/datasets/__pycache__/kinetics.cpython-312.pyc,,
torchvision/datasets/__pycache__/kitti.cpython-312.pyc,,
torchvision/datasets/__pycache__/lfw.cpython-312.pyc,,
torchvision/datasets/__pycache__/lsun.cpython-312.pyc,,
torchvision/datasets/__pycache__/mnist.cpython-312.pyc,,
torchvision/datasets/__pycache__/moving_mnist.cpython-312.pyc,,
torchvision/datasets/__pycache__/omniglot.cpython-312.pyc,,
torchvision/datasets/__pycache__/oxford_iiit_pet.cpython-312.pyc,,
torchvision/datasets/__pycache__/pcam.cpython-312.pyc,,
torchvision/datasets/__pycache__/phototour.cpython-312.pyc,,
torchvision/datasets/__pycache__/places365.cpython-312.pyc,,
torchvision/datasets/__pycache__/rendered_sst2.cpython-312.pyc,,
torchvision/datasets/__pycache__/sbd.cpython-312.pyc,,
torchvision/datasets/__pycache__/sbu.cpython-312.pyc,,
torchvision/datasets/__pycache__/semeion.cpython-312.pyc,,
torchvision/datasets/__pycache__/stanford_cars.cpython-312.pyc,,
torchvision/datasets/__pycache__/stl10.cpython-312.pyc,,
torchvision/datasets/__pycache__/sun397.cpython-312.pyc,,
torchvision/datasets/__pycache__/svhn.cpython-312.pyc,,
torchvision/datasets/__pycache__/ucf101.cpython-312.pyc,,
torchvision/datasets/__pycache__/usps.cpython-312.pyc,,
torchvision/datasets/__pycache__/utils.cpython-312.pyc,,
torchvision/datasets/__pycache__/video_utils.cpython-312.pyc,,
torchvision/datasets/__pycache__/vision.cpython-312.pyc,,
torchvision/datasets/__pycache__/voc.cpython-312.pyc,,
torchvision/datasets/__pycache__/widerface.cpython-312.pyc,,
torchvision/datasets/_optical_flow.py,,
torchvision/datasets/_stereo_matching.py,,
torchvision/datasets/caltech.py,,
torchvision/datasets/celeba.py,,
torchvision/datasets/cifar.py,,
torchvision/datasets/cityscapes.py,,
torchvision/datasets/clevr.py,,
torchvision/datasets/coco.py,,
torchvision/datasets/country211.py,,
torchvision/datasets/dtd.py,,
torchvision/datasets/eurosat.py,,
torchvision/datasets/fakedata.py,,
torchvision/datasets/fer2013.py,,
torchvision/datasets/fgvc_aircraft.py,,
torchvision/datasets/flickr.py,,
torchvision/datasets/flowers102.py,,
torchvision/datasets/folder.py,,
torchvision/datasets/food101.py,,
torchvision/datasets/gtsrb.py,,
torchvision/datasets/hmdb51.py,,
torchvision/datasets/imagenet.py,,
torchvision/datasets/imagenette.py,,
torchvision/datasets/inaturalist.py,,
torchvision/datasets/kinetics.py,,
torchvision/datasets/kitti.py,,
torchvision/datasets/lfw.py,,
torchvision/datasets/lsun.py,,
torchvision/datasets/mnist.py,,
torchvision/datasets/moving_mnist.py,,
torchvision/datasets/omniglot.py,,
torchvision/datasets/oxford_iiit_pet.py,,
torchvision/datasets/pcam.py,,
torchvision/datasets/phototour.py,,
torchvision/datasets/places365.py,,
torchvision/datasets/rendered_sst2.py,,
torchvision/datasets/samplers/__init__.py,,
torchvision/datasets/samplers/__pycache__/__init__.cpython-312.pyc,,
torchvision/datasets/samplers/__pycache__/clip_sampler.cpython-312.pyc,,
torchvision/datasets/samplers/clip_sampler.py,,
torchvision/datasets/sbd.py,,
torchvision/datasets/sbu.py,,
torchvision/datasets/semeion.py,,
torchvision/datasets/stanford_cars.py,,
torchvision/datasets/stl10.py,,
torchvision/datasets/sun397.py,,
torchvision/datasets/svhn.py,,
torchvision/datasets/ucf101.py,,
torchvision/datasets/usps.py,,
torchvision/datasets/utils.py,,
torchvision/datasets/video_utils.py,,
torchvision/datasets/vision.py,,
torchvision/datasets/voc.py,,
torchvision/datasets/widerface.py,,
torchvision/extension.py,,
torchvision/image.pyd,,
torchvision/io/__init__.py,,
torchvision/io/__pycache__/__init__.cpython-312.pyc,,
torchvision/io/__pycache__/_load_gpu_decoder.cpython-312.pyc,,
torchvision/io/__pycache__/_video_deprecation_warning.cpython-312.pyc,,
torchvision/io/__pycache__/_video_opt.cpython-312.pyc,,
torchvision/io/__pycache__/image.cpython-312.pyc,,
torchvision/io/__pycache__/video.cpython-312.pyc,,
torchvision/io/__pycache__/video_reader.cpython-312.pyc,,
torchvision/io/_load_gpu_decoder.py,,
torchvision/io/_video_deprecation_warning.py,,
torchvision/io/_video_opt.py,,
torchvision/io/image.py,,
torchvision/io/video.py,,
torchvision/io/video_reader.py,,
torchvision/jpeg8.dll,,
torchvision/libjpeg.dll,,
torchvision/libpng16.dll,,
torchvision/libsharpyuv.dll,,
torchvision/libwebp.dll,,
torchvision/models/__init__.py,,
torchvision/models/__pycache__/__init__.cpython-312.pyc,,
torchvision/models/__pycache__/_api.cpython-312.pyc,,
torchvision/models/__pycache__/_meta.cpython-312.pyc,,
torchvision/models/__pycache__/_utils.cpython-312.pyc,,
torchvision/models/__pycache__/alexnet.cpython-312.pyc,,
torchvision/models/__pycache__/convnext.cpython-312.pyc,,
torchvision/models/__pycache__/densenet.cpython-312.pyc,,
torchvision/models/__pycache__/efficientnet.cpython-312.pyc,,
torchvision/models/__pycache__/feature_extraction.cpython-312.pyc,,
torchvision/models/__pycache__/googlenet.cpython-312.pyc,,
torchvision/models/__pycache__/inception.cpython-312.pyc,,
torchvision/models/__pycache__/maxvit.cpython-312.pyc,,
torchvision/models/__pycache__/mnasnet.cpython-312.pyc,,
torchvision/models/__pycache__/mobilenet.cpython-312.pyc,,
torchvision/models/__pycache__/mobilenetv2.cpython-312.pyc,,
torchvision/models/__pycache__/mobilenetv3.cpython-312.pyc,,
torchvision/models/__pycache__/regnet.cpython-312.pyc,,
torchvision/models/__pycache__/resnet.cpython-312.pyc,,
torchvision/models/__pycache__/shufflenetv2.cpython-312.pyc,,
torchvision/models/__pycache__/squeezenet.cpython-312.pyc,,
torchvision/models/__pycache__/swin_transformer.cpython-312.pyc,,
torchvision/models/__pycache__/vgg.cpython-312.pyc,,
torchvision/models/__pycache__/vision_transformer.cpython-312.pyc,,
torchvision/models/_api.py,,
torchvision/models/_meta.py,,
torchvision/models/_utils.py,,
torchvision/models/alexnet.py,,
torchvision/models/convnext.py,,
torchvision/models/densenet.py,,
torchvision/models/detection/__init__.py,,
torchvision/models/detection/__pycache__/__init__.cpython-312.pyc,,
torchvision/models/detection/__pycache__/_utils.cpython-312.pyc,,
torchvision/models/detection/__pycache__/anchor_utils.cpython-312.pyc,,
torchvision/models/detection/__pycache__/backbone_utils.cpython-312.pyc,,
torchvision/models/detection/__pycache__/faster_rcnn.cpython-312.pyc,,
torchvision/models/detection/__pycache__/fcos.cpython-312.pyc,,
torchvision/models/detection/__pycache__/generalized_rcnn.cpython-312.pyc,,
torchvision/models/detection/__pycache__/image_list.cpython-312.pyc,,
torchvision/models/detection/__pycache__/keypoint_rcnn.cpython-312.pyc,,
torchvision/models/detection/__pycache__/mask_rcnn.cpython-312.pyc,,
torchvision/models/detection/__pycache__/retinanet.cpython-312.pyc,,
torchvision/models/detection/__pycache__/roi_heads.cpython-312.pyc,,
torchvision/models/detection/__pycache__/rpn.cpython-312.pyc,,
torchvision/models/detection/__pycache__/ssd.cpython-312.pyc,,
torchvision/models/detection/__pycache__/ssdlite.cpython-312.pyc,,
torchvision/models/detection/__pycache__/transform.cpython-312.pyc,,
torchvision/models/detection/_utils.py,,
torchvision/models/detection/anchor_utils.py,,
torchvision/models/detection/backbone_utils.py,,
torchvision/models/detection/faster_rcnn.py,,
torchvision/models/detection/fcos.py,,
torchvision/models/detection/generalized_rcnn.py,,
torchvision/models/detection/image_list.py,,
torchvision/models/detection/keypoint_rcnn.py,,
torchvision/models/detection/mask_rcnn.py,,
torchvision/models/detection/retinanet.py,,
torchvision/models/detection/roi_heads.py,,
torchvision/models/detection/rpn.py,,
torchvision/models/detection/ssd.py,,
torchvision/models/detection/ssdlite.py,,
torchvision/models/detection/transform.py,,
torchvision/models/efficientnet.py,,
torchvision/models/feature_extraction.py,,
torchvision/models/googlenet.py,,
torchvision/models/inception.py,,
torchvision/models/maxvit.py,,
torchvision/models/mnasnet.py,,
torchvision/models/mobilenet.py,,
torchvision/models/mobilenetv2.py,,
torchvision/models/mobilenetv3.py,,
torchvision/models/optical_flow/__init__.py,,
torchvision/models/optical_flow/__pycache__/__init__.cpython-312.pyc,,
torchvision/models/optical_flow/__pycache__/_utils.cpython-312.pyc,,
torchvision/models/optical_flow/__pycache__/raft.cpython-312.pyc,,
torchvision/models/optical_flow/_utils.py,,
torchvision/models/optical_flow/raft.py,,
torchvision/models/quantization/__init__.py,,
torchvision/models/quantization/__pycache__/__init__.cpython-312.pyc,,
torchvision/models/quantization/__pycache__/googlenet.cpython-312.pyc,,
torchvision/models/quantization/__pycache__/inception.cpython-312.pyc,,
torchvision/models/quantization/__pycache__/mobilenet.cpython-312.pyc,,
torchvision/models/quantization/__pycache__/mobilenetv2.cpython-312.pyc,,
torchvision/models/quantization/__pycache__/mobilenetv3.cpython-312.pyc,,
torchvision/models/quantization/__pycache__/resnet.cpython-312.pyc,,
torchvision/models/quantization/__pycache__/shufflenetv2.cpython-312.pyc,,
torchvision/models/quantization/__pycache__/utils.cpython-312.pyc,,
torchvision/models/quantization/googlenet.py,,
torchvision/models/quantization/inception.py,,
torchvision/models/quantization/mobilenet.py,,
torchvision/models/quantization/mobilenetv2.py,,
torchvision/models/quantization/mobilenetv3.py,,
torchvision/models/quantization/resnet.py,,
torchvision/models/quantization/shufflenetv2.py,,
torchvision/models/quantization/utils.py,,
torchvision/models/regnet.py,,
torchvision/models/resnet.py,,
torchvision/models/segmentation/__init__.py,,
torchvision/models/segmentation/__pycache__/__init__.cpython-312.pyc,,
torchvision/models/segmentation/__pycache__/_utils.cpython-312.pyc,,
torchvision/models/segmentation/__pycache__/deeplabv3.cpython-312.pyc,,
torchvision/models/segmentation/__pycache__/fcn.cpython-312.pyc,,
torchvision/models/segmentation/__pycache__/lraspp.cpython-312.pyc,,
torchvision/models/segmentation/_utils.py,,
torchvision/models/segmentation/deeplabv3.py,,
torchvision/models/segmentation/fcn.py,,
torchvision/models/segmentation/lraspp.py,,
torchvision/models/shufflenetv2.py,,
torchvision/models/squeezenet.py,,
torchvision/models/swin_transformer.py,,
torchvision/models/vgg.py,,
torchvision/models/video/__init__.py,,
torchvision/models/video/__pycache__/__init__.cpython-312.pyc,,
torchvision/models/video/__pycache__/mvit.cpython-312.pyc,,
torchvision/models/video/__pycache__/resnet.cpython-312.pyc,,
torchvision/models/video/__pycache__/s3d.cpython-312.pyc,,
torchvision/models/video/__pycache__/swin_transformer.cpython-312.pyc,,
torchvision/models/video/mvit.py,,
torchvision/models/video/resnet.py,,
torchvision/models/video/s3d.py,,
torchvision/models/video/swin_transformer.py,,
torchvision/models/vision_transformer.py,,
torchvision/nvjpeg64_12.dll,,
torchvision/ops/__init__.py,,
torchvision/ops/__pycache__/__init__.cpython-312.pyc,,
torchvision/ops/__pycache__/_box_convert.cpython-312.pyc,,
torchvision/ops/__pycache__/_register_onnx_ops.cpython-312.pyc,,
torchvision/ops/__pycache__/_utils.cpython-312.pyc,,
torchvision/ops/__pycache__/boxes.cpython-312.pyc,,
torchvision/ops/__pycache__/ciou_loss.cpython-312.pyc,,
torchvision/ops/__pycache__/deform_conv.cpython-312.pyc,,
torchvision/ops/__pycache__/diou_loss.cpython-312.pyc,,
torchvision/ops/__pycache__/drop_block.cpython-312.pyc,,
torchvision/ops/__pycache__/feature_pyramid_network.cpython-312.pyc,,
torchvision/ops/__pycache__/focal_loss.cpython-312.pyc,,
torchvision/ops/__pycache__/giou_loss.cpython-312.pyc,,
torchvision/ops/__pycache__/misc.cpython-312.pyc,,
torchvision/ops/__pycache__/poolers.cpython-312.pyc,,
torchvision/ops/__pycache__/ps_roi_align.cpython-312.pyc,,
torchvision/ops/__pycache__/ps_roi_pool.cpython-312.pyc,,
torchvision/ops/__pycache__/roi_align.cpython-312.pyc,,
torchvision/ops/__pycache__/roi_pool.cpython-312.pyc,,
torchvision/ops/__pycache__/stochastic_depth.cpython-312.pyc,,
torchvision/ops/_box_convert.py,,
torchvision/ops/_register_onnx_ops.py,,
torchvision/ops/_utils.py,,
torchvision/ops/boxes.py,,
torchvision/ops/ciou_loss.py,,
torchvision/ops/deform_conv.py,,
torchvision/ops/diou_loss.py,,
torchvision/ops/drop_block.py,,
torchvision/ops/feature_pyramid_network.py,,
torchvision/ops/focal_loss.py,,
torchvision/ops/giou_loss.py,,
torchvision/ops/misc.py,,
torchvision/ops/poolers.py,,
torchvision/ops/ps_roi_align.py,,
torchvision/ops/ps_roi_pool.py,,
torchvision/ops/roi_align.py,,
torchvision/ops/roi_pool.py,,
torchvision/ops/stochastic_depth.py,,
torchvision/prototype/__init__.py,,
torchvision/prototype/__pycache__/__init__.cpython-312.pyc,,
torchvision/prototype/datasets/__init__.py,,
torchvision/prototype/datasets/__pycache__/__init__.cpython-312.pyc,,
torchvision/prototype/datasets/__pycache__/_api.cpython-312.pyc,,
torchvision/prototype/datasets/__pycache__/_folder.cpython-312.pyc,,
torchvision/prototype/datasets/__pycache__/_home.cpython-312.pyc,,
torchvision/prototype/datasets/__pycache__/benchmark.cpython-312.pyc,,
torchvision/prototype/datasets/__pycache__/generate_category_files.cpython-312.pyc,,
torchvision/prototype/datasets/_api.py,,
torchvision/prototype/datasets/_builtin/__init__.py,,
torchvision/prototype/datasets/_builtin/__pycache__/__init__.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/caltech.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/celeba.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/cifar.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/clevr.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/coco.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/country211.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/cub200.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/dtd.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/eurosat.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/fer2013.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/food101.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/gtsrb.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/imagenet.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/mnist.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/oxford_iiit_pet.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/pcam.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/sbd.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/semeion.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/stanford_cars.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/svhn.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/usps.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/__pycache__/voc.cpython-312.pyc,,
torchvision/prototype/datasets/_builtin/caltech.py,,
torchvision/prototype/datasets/_builtin/caltech101.categories,,
torchvision/prototype/datasets/_builtin/caltech256.categories,,
torchvision/prototype/datasets/_builtin/celeba.py,,
torchvision/prototype/datasets/_builtin/cifar.py,,
torchvision/prototype/datasets/_builtin/cifar10.categories,,
torchvision/prototype/datasets/_builtin/cifar100.categories,,
torchvision/prototype/datasets/_builtin/clevr.py,,
torchvision/prototype/datasets/_builtin/coco.categories,,
torchvision/prototype/datasets/_builtin/coco.py,,
torchvision/prototype/datasets/_builtin/country211.categories,,
torchvision/prototype/datasets/_builtin/country211.py,,
torchvision/prototype/datasets/_builtin/cub200.categories,,
torchvision/prototype/datasets/_builtin/cub200.py,,
torchvision/prototype/datasets/_builtin/dtd.categories,,
torchvision/prototype/datasets/_builtin/dtd.py,,
torchvision/prototype/datasets/_builtin/eurosat.py,,
torchvision/prototype/datasets/_builtin/fer2013.py,,
torchvision/prototype/datasets/_builtin/food101.categories,,
torchvision/prototype/datasets/_builtin/food101.py,,
torchvision/prototype/datasets/_builtin/gtsrb.py,,
torchvision/prototype/datasets/_builtin/imagenet.categories,,
torchvision/prototype/datasets/_builtin/imagenet.py,,
torchvision/prototype/datasets/_builtin/mnist.py,,
torchvision/prototype/datasets/_builtin/oxford-iiit-pet.categories,,
torchvision/prototype/datasets/_builtin/oxford_iiit_pet.py,,
torchvision/prototype/datasets/_builtin/pcam.py,,
torchvision/prototype/datasets/_builtin/sbd.categories,,
torchvision/prototype/datasets/_builtin/sbd.py,,
torchvision/prototype/datasets/_builtin/semeion.py,,
torchvision/prototype/datasets/_builtin/stanford-cars.categories,,
torchvision/prototype/datasets/_builtin/stanford_cars.py,,
torchvision/prototype/datasets/_builtin/svhn.py,,
torchvision/prototype/datasets/_builtin/usps.py,,
torchvision/prototype/datasets/_builtin/voc.categories,,
torchvision/prototype/datasets/_builtin/voc.py,,
torchvision/prototype/datasets/_folder.py,,
torchvision/prototype/datasets/_home.py,,
torchvision/prototype/datasets/benchmark.py,,
torchvision/prototype/datasets/generate_category_files.py,,
torchvision/prototype/datasets/utils/__init__.py,,
torchvision/prototype/datasets/utils/__pycache__/__init__.cpython-312.pyc,,
torchvision/prototype/datasets/utils/__pycache__/_dataset.cpython-312.pyc,,
torchvision/prototype/datasets/utils/__pycache__/_encoded.cpython-312.pyc,,
torchvision/prototype/datasets/utils/__pycache__/_internal.cpython-312.pyc,,
torchvision/prototype/datasets/utils/__pycache__/_resource.cpython-312.pyc,,
torchvision/prototype/datasets/utils/_dataset.py,,
torchvision/prototype/datasets/utils/_encoded.py,,
torchvision/prototype/datasets/utils/_internal.py,,
torchvision/prototype/datasets/utils/_resource.py,,
torchvision/prototype/models/__init__.py,,
torchvision/prototype/models/__pycache__/__init__.cpython-312.pyc,,
torchvision/prototype/models/depth/__init__.py,,
torchvision/prototype/models/depth/__pycache__/__init__.cpython-312.pyc,,
torchvision/prototype/models/depth/stereo/__init__.py,,
torchvision/prototype/models/depth/stereo/__pycache__/__init__.cpython-312.pyc,,
torchvision/prototype/models/depth/stereo/__pycache__/crestereo.cpython-312.pyc,,
torchvision/prototype/models/depth/stereo/__pycache__/raft_stereo.cpython-312.pyc,,
torchvision/prototype/models/depth/stereo/crestereo.py,,
torchvision/prototype/models/depth/stereo/raft_stereo.py,,
torchvision/prototype/transforms/__init__.py,,
torchvision/prototype/transforms/__pycache__/__init__.cpython-312.pyc,,
torchvision/prototype/transforms/__pycache__/_augment.cpython-312.pyc,,
torchvision/prototype/transforms/__pycache__/_geometry.cpython-312.pyc,,
torchvision/prototype/transforms/__pycache__/_misc.cpython-312.pyc,,
torchvision/prototype/transforms/__pycache__/_presets.cpython-312.pyc,,
torchvision/prototype/transforms/__pycache__/_type_conversion.cpython-312.pyc,,
torchvision/prototype/transforms/_augment.py,,
torchvision/prototype/transforms/_geometry.py,,
torchvision/prototype/transforms/_misc.py,,
torchvision/prototype/transforms/_presets.py,,
torchvision/prototype/transforms/_type_conversion.py,,
torchvision/prototype/tv_tensors/__init__.py,,
torchvision/prototype/tv_tensors/__pycache__/__init__.cpython-312.pyc,,
torchvision/prototype/tv_tensors/__pycache__/_label.cpython-312.pyc,,
torchvision/prototype/tv_tensors/_label.py,,
torchvision/prototype/utils/__init__.py,,
torchvision/prototype/utils/__pycache__/__init__.cpython-312.pyc,,
torchvision/prototype/utils/__pycache__/_internal.cpython-312.pyc,,
torchvision/prototype/utils/_internal.py,,
torchvision/python312.dll,,
torchvision/transforms/__init__.py,,
torchvision/transforms/__pycache__/__init__.cpython-312.pyc,,
torchvision/transforms/__pycache__/_functional_pil.cpython-312.pyc,,
torchvision/transforms/__pycache__/_functional_tensor.cpython-312.pyc,,
torchvision/transforms/__pycache__/_functional_video.cpython-312.pyc,,
torchvision/transforms/__pycache__/_presets.cpython-312.pyc,,
torchvision/transforms/__pycache__/_transforms_video.cpython-312.pyc,,
torchvision/transforms/__pycache__/autoaugment.cpython-312.pyc,,
torchvision/transforms/__pycache__/functional.cpython-312.pyc,,
torchvision/transforms/__pycache__/transforms.cpython-312.pyc,,
torchvision/transforms/_functional_pil.py,,
torchvision/transforms/_functional_tensor.py,,
torchvision/transforms/_functional_video.py,,
torchvision/transforms/_presets.py,,
torchvision/transforms/_transforms_video.py,,
torchvision/transforms/autoaugment.py,,
torchvision/transforms/functional.py,,
torchvision/transforms/transforms.py,,
torchvision/transforms/v2/__init__.py,,
torchvision/transforms/v2/__pycache__/__init__.cpython-312.pyc,,
torchvision/transforms/v2/__pycache__/_augment.cpython-312.pyc,,
torchvision/transforms/v2/__pycache__/_auto_augment.cpython-312.pyc,,
torchvision/transforms/v2/__pycache__/_color.cpython-312.pyc,,
torchvision/transforms/v2/__pycache__/_container.cpython-312.pyc,,
torchvision/transforms/v2/__pycache__/_deprecated.cpython-312.pyc,,
torchvision/transforms/v2/__pycache__/_geometry.cpython-312.pyc,,
torchvision/transforms/v2/__pycache__/_meta.cpython-312.pyc,,
torchvision/transforms/v2/__pycache__/_misc.cpython-312.pyc,,
torchvision/transforms/v2/__pycache__/_temporal.cpython-312.pyc,,
torchvision/transforms/v2/__pycache__/_transform.cpython-312.pyc,,
torchvision/transforms/v2/__pycache__/_type_conversion.cpython-312.pyc,,
torchvision/transforms/v2/__pycache__/_utils.cpython-312.pyc,,
torchvision/transforms/v2/_augment.py,,
torchvision/transforms/v2/_auto_augment.py,,
torchvision/transforms/v2/_color.py,,
torchvision/transforms/v2/_container.py,,
torchvision/transforms/v2/_deprecated.py,,
torchvision/transforms/v2/_geometry.py,,
torchvision/transforms/v2/_meta.py,,
torchvision/transforms/v2/_misc.py,,
torchvision/transforms/v2/_temporal.py,,
torchvision/transforms/v2/_transform.py,,
torchvision/transforms/v2/_type_conversion.py,,
torchvision/transforms/v2/_utils.py,,
torchvision/transforms/v2/functional/__init__.py,,
torchvision/transforms/v2/functional/__pycache__/__init__.cpython-312.pyc,,
torchvision/transforms/v2/functional/__pycache__/_augment.cpython-312.pyc,,
torchvision/transforms/v2/functional/__pycache__/_color.cpython-312.pyc,,
torchvision/transforms/v2/functional/__pycache__/_deprecated.cpython-312.pyc,,
torchvision/transforms/v2/functional/__pycache__/_geometry.cpython-312.pyc,,
torchvision/transforms/v2/functional/__pycache__/_meta.cpython-312.pyc,,
torchvision/transforms/v2/functional/__pycache__/_misc.cpython-312.pyc,,
torchvision/transforms/v2/functional/__pycache__/_temporal.cpython-312.pyc,,
torchvision/transforms/v2/functional/__pycache__/_type_conversion.cpython-312.pyc,,
torchvision/transforms/v2/functional/__pycache__/_utils.cpython-312.pyc,,
torchvision/transforms/v2/functional/_augment.py,,
torchvision/transforms/v2/functional/_color.py,,
torchvision/transforms/v2/functional/_deprecated.py,,
torchvision/transforms/v2/functional/_geometry.py,,
torchvision/transforms/v2/functional/_meta.py,,
torchvision/transforms/v2/functional/_misc.py,,
torchvision/transforms/v2/functional/_temporal.py,,
torchvision/transforms/v2/functional/_type_conversion.py,,
torchvision/transforms/v2/functional/_utils.py,,
torchvision/tv_tensors/__init__.py,,
torchvision/tv_tensors/__pycache__/__init__.cpython-312.pyc,,
torchvision/tv_tensors/__pycache__/_bounding_boxes.cpython-312.pyc,,
torchvision/tv_tensors/__pycache__/_dataset_wrapper.cpython-312.pyc,,
torchvision/tv_tensors/__pycache__/_image.cpython-312.pyc,,
torchvision/tv_tensors/__pycache__/_keypoints.cpython-312.pyc,,
torchvision/tv_tensors/__pycache__/_mask.cpython-312.pyc,,
torchvision/tv_tensors/__pycache__/_torch_function_helpers.cpython-312.pyc,,
torchvision/tv_tensors/__pycache__/_tv_tensor.cpython-312.pyc,,
torchvision/tv_tensors/__pycache__/_video.cpython-312.pyc,,
torchvision/tv_tensors/_bounding_boxes.py,,
torchvision/tv_tensors/_dataset_wrapper.py,,
torchvision/tv_tensors/_image.py,,
torchvision/tv_tensors/_keypoints.py,,
torchvision/tv_tensors/_mask.py,,
torchvision/tv_tensors/_torch_function_helpers.py,,
torchvision/tv_tensors/_tv_tensor.py,,
torchvision/tv_tensors/_video.py,,
torchvision/utils.py,,
torchvision/version.py,,
torchvision/zlib.dll,,
torchvision\_C.pyd,sha256=4fPHnITcPqOGSqIUiH4spFm9Ybuq1iB4mV1v9dpBOc8,7342592
torchvision\__init__.py,sha256=yUybb2eKRBX2LWsDZPAnEpHWtEFcGHS-Xo5r8K-Ric0,3639
torchvision\_internally_replaced_utils.py,sha256=LogrBRyA6oM0joW1_kzgVYicV6ZYCFsszHbcuPxgGSA,1458
torchvision\_meta_registrations.py,sha256=_rNIAEDFkHMmgYGm982-WgSmhA9o2KVJpd8DsoUlQmk,7433
torchvision\_utils.py,sha256=8TvBoMxnfm9Ow4ypvjoWxrF7hKwJ2hX5UUxN209zbV8,988
torchvision\cudart64_12.dll,sha256=wsmpwiqby6kOJhgllog2eHszEDgEeiZ3DP-3pYPCg0Q,573952
torchvision\datasets\__init__.py,sha256=Ajw_RJcPNYz-iKvkvQEkgw2P341llDsDgd8cke-bxas,3753
torchvision\datasets\_optical_flow.py,sha256=tQOwa1VOvDIr69xWnpFa-eBJ5Kg5oVBM0ceDpXNvSTE,21720
torchvision\datasets\_stereo_matching.py,sha256=i1JemwbjQhsiMLB3Hrmdo4vYpX4FcNjGpdDQAYF_Pdc,50263
torchvision\datasets\caltech.py,sha256=TFgTrxDPfpIxRm7rfcWdpyTUIylkZNMG1lNBeInUUgk,9170
torchvision\datasets\celeba.py,sha256=B-bqLqcpRVLHqa9hsMZbhg8J310D4HeeicnqKNOD6OU,8741
torchvision\datasets\cifar.py,sha256=1T71RgltoNVjjWxjCUSRBCQh6Bf_O50Sim8w3cOA40Q,5951
torchvision\datasets\cityscapes.py,sha256=BPT91qlUiaCz7Zve2bhTTlnKUR11TEOgJdex_CPuwwg,10552
torchvision\datasets\clevr.py,sha256=VdRijEXJBsR1ED-z0FjJUj7QVF7tEgmPHwflamXe1DU,3948
torchvision\datasets\coco.py,sha256=KS_Ny3rtnahIZ7vzILgjWCnnupIHnVB6UVYV1pMHnOE,4456
torchvision\datasets\country211.py,sha256=aw2FzdX-OTQtvHFldL7p5CVA02-7Qt6AXX6j4UQEC8M,2956
torchvision\datasets\dtd.py,sha256=QkPVyrfzJBwVfSWjwk2m7Gx8fOxDG8KUsvZJ18lTJ4E,4525
torchvision\datasets\eurosat.py,sha256=vLcnf6XlVIT9MG1ZTPB8kfY10TXqTJcZ6QelpQNmqSE,2832
torchvision\datasets\fakedata.py,sha256=pdSyCMLTLSW0KWIoYgTbPv0rcYFWj8p6J7vjODl7h0o,2507
torchvision\datasets\fer2013.py,sha256=Clw7azQ4RpapE2giqWK-eOUiR-SuYwfOM5ikjaOAYLc,5226
torchvision\datasets\fgvc_aircraft.py,sha256=4RblkmHUiXoxFngtnIL1iDpiHhe29pKGt5f51d7ptPk,5088
torchvision\datasets\flickr.py,sha256=v5zMcyDQcnzCvp7Y4qN6560q_lFSyBB3Poq0S1eFwyI,6346
torchvision\datasets\flowers102.py,sha256=luufpQWTl9rdFTPQheQBbOlzV8edFOaAxnZnDMenpmk,7706
torchvision\datasets\folder.py,sha256=68dCiaX8Pvv8JIiuIhbx0kaVIyp22RyST8zOnxB2YBc,13322
torchvision\datasets\food101.py,sha256=KGA1JCwbXBEbEQjbuyhsiCEldsfFlLahFies35IMkxQ,4243
torchvision\datasets\gtsrb.py,sha256=pERh6_VqsEPJKXYMY1UdiyZTjrl8cp2g6og04ifgIp0,3881
torchvision\datasets\hmdb51.py,sha256=FKxcu2yOGSQVCqZ7kir2VFxzR7h7XjlM7yP-Xiv4oic,6104
torchvision\datasets\imagenet.py,sha256=758dmmmpAm8HN4PZ2Z9sqj6QmyhO6D-bvkWj7eKsIE4,9144
torchvision\datasets\imagenette.py,sha256=LmLm2dq98tv5Znw31tH09cO26VyYZK3YcEJ6hrXALXE,4730
torchvision\datasets\inaturalist.py,sha256=KiWpvP3kBTel1vor198wjZ68X4xv0q83_SNsTb4Eo38,10547
torchvision\datasets\kinetics.py,sha256=ujFVpL3yrbLWwLQs8g0_TS8JWKWzqNN6P_TpBEnqtZo,10102
torchvision\datasets\kitti.py,sha256=XsFC8DaCCMiwvs20Qtyxpltr-7yDj4A1_CSVGO6UdE0,5782
torchvision\datasets\lfw.py,sha256=WT1g-zKyszYDArSTBA-r-nU1yRhLobgevi13GhS0DRA,11671
torchvision\datasets\lsun.py,sha256=EaPp0k9EcCktMoN12dAGbuu92PuxVtEzUOTyycN_RdU,5898
torchvision\datasets\mnist.py,sha256=yhBEtZ2CZqCybEo0fDLcXjL9WGpS8ISy-pqzl7xE0vo,22364
torchvision\datasets\moving_mnist.py,sha256=Cmw-Pj4xEzmfGZab5O0SGHjxYntg7lyL6XCwuzr1FTQ,3738
torchvision\datasets\omniglot.py,sha256=e51DpqaTFrffgrT3g_HoCCB26xqAa6ILo1FQxC_kwTU,4593
torchvision\datasets\oxford_iiit_pet.py,sha256=cl4OoiEw5l2QzjUcl1ZsSOeTcChM1gTR_eURvP2HErs,5831
torchvision\datasets\pcam.py,sha256=QROSVEEcVZ7WP_GNmUBzot49r54jQ2PzhW8cqFuRbrw,5412
torchvision\datasets\phototour.py,sha256=7ZT9Le--HQU87kzWw1qTDL8UZdLcLJDSsyMzcvh_bKk,8085
torchvision\datasets\places365.py,sha256=z7XKs8zVImJvvcrh0nt0FnlrP9Xz1rZ6oEDnSnObMmg,7643
torchvision\datasets\rendered_sst2.py,sha256=FMlBdmva-_oWor7uSgDFH4HlYm8EoE0QyenTPrSALD8,4046
torchvision\datasets\samplers\__init__.py,sha256=yX8XD3h-VwTCoqF9IdQmcuGblZxvXb2EIqc5lPqXXtY,164
torchvision\datasets\samplers\clip_sampler.py,sha256=oBhAHsW7BYEKGnUtJ7EqCYy3yTtJYahofAdSPcKiHtA,6438
torchvision\datasets\sbd.py,sha256=STXgWtZNOJ_P6pj4nYwR9p7HjjPLmLz26b8O5qH_T0Q,5533
torchvision\datasets\sbu.py,sha256=oEQZm7y5Xu_XMT3WN-PGTpy864IT-Y4CWCeLaeitsKI,4578
torchvision\datasets\semeion.py,sha256=klYpsKYYuYAZpLylwp3OQX9HBWcKfyJipTDpW3B47H4,3191
torchvision\datasets\stanford_cars.py,sha256=ezj66uMKHejcdkGY0Im6rhRbRvrGKH_F482Ne-gwLC4,4386
torchvision\datasets\stl10.py,sha256=lWXtiNAbbRQxVMTnHIY74pfl5vZWsjM3jiGIcWFq0Co,7401
torchvision\datasets\sun397.py,sha256=fDAmuyll2fw-Wph6cckmpsar9fm3xtAkjq3a7gRiruQ,3257
torchvision\datasets\svhn.py,sha256=TEzQE4RUgwdH-ezfDib-sdQD1ORpQM6YWn_WJF4zmMM,4951
torchvision\datasets\ucf101.py,sha256=vTTf8KY82qKdd8HuHY1NcM_ZUt0Bu53BOF0eFZc-820,5645
torchvision\datasets\usps.py,sha256=74zymHuzkJenGD_5Gbd2aV_Wsi9R7E-1Xsd-tbr-1vU,3605
torchvision\datasets\utils.py,sha256=F_NX_BoNlomVt-MlFJ0mpud34Nj7IrLN3OjvLZjb1WA,16382
torchvision\datasets\video_utils.py,sha256=rfroJInqA3iFZ7hOgRA7e6mddYcM904bsmZg2oGKf44,17613
torchvision\datasets\vision.py,sha256=s3_TFYSzplp-TSLDW_QNu4z0Xpua48D5iDZjJDQo__I,4347
torchvision\datasets\voc.py,sha256=cFi8zSfU8CSig6dvnQIBEnjEMVqJEE5Jgs6e8ehojnA,9040
torchvision\datasets\widerface.py,sha256=jQpfLZ2by9F8ABigruWY6nDQwMfAv4z63IZQ9XwC43s,8437
torchvision\extension.py,sha256=0A4efQ6V8RlQcMMtDpK74VIBHpDv4icjkkOc-EokPHw,3233
torchvision\image.pyd,sha256=yDvXmQ7jwwxSOAjOatyRgHCzGRWPifVbCPOG95pTDlE,304128
torchvision\io\__init__.py,sha256=gzG3Qr6eYLnwemcJFTmWwL8g4Bfd3K9BRVydqo2EnY4,1656
torchvision\io\_load_gpu_decoder.py,sha256=vUWhEXG1Dq3pIJHd8avo4o333Z7zx2DN7FOzIxuGluE,186
torchvision\io\_video_deprecation_warning.py,sha256=uBhKhr7iAK2vECUCT9RoKSlidAHbgGLPT8bfQr9zLGA,581
torchvision\io\_video_opt.py,sha256=quiNhMJnXC2oI2_Y-4wRbblPajs6Z5sMT6yEuN76M0g,21304
torchvision\io\image.py,sha256=IiBCdqcDWj_c7aLsVlD-M72vo2-IFKF_-hyKDrVo-4M,22223
torchvision\io\video.py,sha256=1TvERcZFZuWEpvt1PxWs65SZmj68PA9Rtf39jL18myM,18806
torchvision\io\video_reader.py,sha256=_myMyJLiiugJtzuHh3HWc-M5l9R-V_kdIT-46dHZMaM,12158
torchvision\jpeg8.dll,sha256=aM-Kj2MkrdHI0gkgpHfh86_icuM26XiMu6gyMGeuKig,552448
torchvision\libjpeg.dll,sha256=qyn4xdAUJAGvpE8dg79mDDsWt55sj-9g0GGVb9zAj6M,285512
torchvision\libpng16.dll,sha256=hku0CxcNuJUhjKsjT3scdPzUz2mec0sTtBEoBd-bgNY,206664
torchvision\libsharpyuv.dll,sha256=W5eBRnuuGzCl3wcHq3RXMMmK2WodsqgluPE1881s-UY,37192
torchvision\libwebp.dll,sha256=6ev4ynB60ulk-M3ZiSyeU2UXhWaWVHxGcfYqfNTTlPY,387912
torchvision\models\__init__.py,sha256=6QlTJfvjKcUmMJvwSapWUNFXbf2Vo15dVRcBuNSaYko,888
torchvision\models\_api.py,sha256=yv71Vl6qY5Dnvh7PtiTSfsq94TIpEjNHcFnpH3pR7VM,10253
torchvision\models\_meta.py,sha256=2NSIICoq4MDzPZc00DlGJTgHOCwTBSObSTeRTh3E0tQ,30429
torchvision\models\_utils.py,sha256=gOh6tA08U7NHLGt6zznG7dLJfi18fWy_Wp_dhaH8xko,11136
torchvision\models\alexnet.py,sha256=XcldP2UuOkdOUfdxitGS8qHzLH78Ny7VCzTzKsaWITU,4607
torchvision\models\convnext.py,sha256=xM6IWUmP3-TSn79_APA4WDSgzL5JSRXvIleJyVmmRYg,15762
torchvision\models\densenet.py,sha256=Q1_8tERSWn2uwhjylxkQlMVcYlirp3ARyxZEiG-Zw2Q,17260
torchvision\models\detection\__init__.py,sha256=D4cs338Z4BQn5TgX2IKuJC9TD2rtw2svUDZlALR-lwI,175
torchvision\models\detection\_utils.py,sha256=dee4UORMRBeHz4YKTOOeyKsEb9Q4AYmL3iG__sfZioM,22646
torchvision\models\detection\anchor_utils.py,sha256=M6Gm4Qrji8DSfR3IVpfS9VHNEpIKT_AEHJlINioIzns,12121
torchvision\models\detection\backbone_utils.py,sha256=SC0TRbPxy3P6Lzq0Z9iYRhHsoIGUex43v7ntyFJUwPU,10780
torchvision\models\detection\faster_rcnn.py,sha256=3ZiR2D3XovDfdIHBJjFfLHwxxfgIDvSfLh-pmMWvNNM,37812
torchvision\models\detection\fcos.py,sha256=0uOtXF6cOZhaSeTIB1rqreAC3XdcD4WXzk4QTMaF89A,34991
torchvision\models\detection\generalized_rcnn.py,sha256=7ovthQx8aEi6oxXovSqO7D7Qanp2yzd1HHXAQbQS3Tk,5062
torchvision\models\detection\image_list.py,sha256=rUmPJI-F1EQ_0nNsNnHrhsMc8fusrDFgUdloMLOJbgo,774
torchvision\models\detection\keypoint_rcnn.py,sha256=nXGqgQ6uhLLYw785Ta3fFKKL7Mc0KFp8QZG0sqY3T7k,22455
torchvision\models\detection\mask_rcnn.py,sha256=W_3sXiSIgFz5gE9fmSh-cw9NAt45CX-TGkLTqp-zvsg,27303
torchvision\models\detection\retinanet.py,sha256=nZNicKRgBZuJh-cM-FqPe9GgaB6GFOIgpopSmz4HE6M,38184
torchvision\models\detection\roi_heads.py,sha256=kzLNPjrU3jtWeXGqaFbdBPKZ4gAO5p77zlOJRiPkRg0,34699
torchvision\models\detection\rpn.py,sha256=AP9-p3_pujcDita2wSiRhbLnU8oSTFDPZNjw0w7ezUM,16205
torchvision\models\detection\ssd.py,sha256=BCU2bgRnPGmxsVFXriz54lsS7Xbdzdfm3N3BmW4OeI8,29642
torchvision\models\detection\ssdlite.py,sha256=_MKsJEExuIUtqrJ-BWcXCpyTK-jE4jjvaOgn4lUjn64,13538
torchvision\models\detection\transform.py,sha256=Jqtqf9uLo0uBEraJ1pDaMBSuALY5_vDELnLCQcOwwm0,12489
torchvision\models\efficientnet.py,sha256=_qqZVYMrNIhUw97v2B_9cgyLprm84hQk8A-X5m6uk4Q,44230
torchvision\models\feature_extraction.py,sha256=wu9xI_QcRW4XXQYggrveacZI74yAWbr7j-ckW8uHj-M,28521
torchvision\models\googlenet.py,sha256=aIlM44ZT8hsuRz3t2RLdcZv1vhYQP_3x8Rc-QGE27RU,13138
torchvision\models\inception.py,sha256=3DNzEmfmschGRrCyA4-mDkRVUBbv7GSnbZa_oaiaVYU,19316
torchvision\models\maxvit.py,sha256=LHPsHqa-RaWIqbbdMrsm2YEk1332RgJS6wIJ-agqPX4,32944
torchvision\models\mnasnet.py,sha256=yMR8vdb4nj1kdUqI8r53ERJNRRjYl4tHlTYkMRh57NU,17996
torchvision\models\mobilenet.py,sha256=alrEJwktmXVcCphU8h2EAJZX0YdKfcz4tJEOdG2BXB8,217
torchvision\models\mobilenetv2.py,sha256=G0ZvYkujutNjjPWJ1aJh-O0d3F02ExdvajeLyZHVr4Y,9964
torchvision\models\mobilenetv3.py,sha256=jIF7HMwQ7fqCPtWY1jw7PT17KMIIVYEXRAq17InrQSI,16724
torchvision\models\optical_flow\__init__.py,sha256=uuRFAdvcDobdAbY2VmxEZ7_CLH_f5-JRkCSuJRkj4RY,21
torchvision\models\optical_flow\_utils.py,sha256=PRcuU-IB6EL3hAOLiyC5q-NBzlvIKfhSF_BMplHbzfY,2125
torchvision\models\optical_flow\raft.py,sha256=H96CpsOcUd5nyX8kFyOyTLWB6sI7txsWUMgqjH1jduM,40938
torchvision\models\quantization\__init__.py,sha256=YOJmYqWQTfP5P2ypteZNKQOMW4VEB2WHJlYoSlSaL1Y,130
torchvision\models\quantization\googlenet.py,sha256=KfUQoqXi8JluXlJ66t2aUBjFNDN0B5Y6zsu29tWdnYQ,8324
torchvision\models\quantization\inception.py,sha256=9cb3yiBYnmaC2vC4LEFYbWPvO8iMFNcYQx6LksHmomc,11116
torchvision\models\quantization\mobilenet.py,sha256=alrEJwktmXVcCphU8h2EAJZX0YdKfcz4tJEOdG2BXB8,217
torchvision\models\quantization\mobilenetv2.py,sha256=xR7Vpq7xcq2GSdsxq6UT6OA5LEPaWFmxF2NnxRFnzVY,6071
torchvision\models\quantization\mobilenetv3.py,sha256=ZNb3egv-RdSjIW2nw6mEn6xE13AQZmDryMdDe1B96yg,9495
torchvision\models\quantization\resnet.py,sha256=0fzTtBt-1iP0CembaGBoRckI2akVSz2MxKzGfBx5xMQ,18547
torchvision\models\quantization\shufflenetv2.py,sha256=jnrMO3Js8rr3EZzAQi4AQvyHo8wl0zr2EqmRRjwU8o8,17441
torchvision\models\quantization\utils.py,sha256=mwO6t0K7PMcev2LLndIEmsXNKvYEJBM4f7NzsiM8jk4,2103
torchvision\models\regnet.py,sha256=vblO9fo8WnU6tbVnNZuHIabNrXyoVHnGVQDru2yRbEU,65105
torchvision\models\resnet.py,sha256=fDKRmPQU5BHdZNZ3hMH377sehb244WC4xdXFYZ-asRk,39905
torchvision\models\segmentation\__init__.py,sha256=TLL2SSmqE08HLiv_yyIWyIyrvf2xaOsZi0muDv_Y5Vc,69
torchvision\models\segmentation\_utils.py,sha256=P8658dSbojoau7DLTiE4RZmDZBX7AfgE2V7FjrP_YXs,1228
torchvision\models\segmentation\deeplabv3.py,sha256=krcN6ustrnFvTmdD2MEc7821lCSUjMWitedz6Zw0IbQ,15433
torchvision\models\segmentation\fcn.py,sha256=mQ1Wi4S9j5G6OQbNciuxNwVbJ6e9miTzIWj6mUF5JwA,9205
torchvision\models\segmentation\lraspp.py,sha256=QvcS-sGmSpJg3HQdi4e09jRLd8nPHIE05_GPbMvryRA,7815
torchvision\models\shufflenetv2.py,sha256=Z-0YBL0T3oLOcjX6CBCj755n3nUbDN0u8-q3xhsTWXY,15846
torchvision\models\squeezenet.py,sha256=Dha-ci350KU15D0LS9N07kw6MlNuusUHSBnC83Ery_E,8986
torchvision\models\swin_transformer.py,sha256=vjt095dNfuvMX1-WEG72tqe_xxAtsBLQytts88L2vB8,40364
torchvision\models\vgg.py,sha256=1SWU2kj-cjL7YDnV0dOh15Om9D_zSt3Ue4d0CjUBIt4,19724
torchvision\models\video\__init__.py,sha256=xHHR5c6kP0cMDXck7XnXq19iJL_Uemcxg3OC00cqE6A,97
torchvision\models\video\mvit.py,sha256=_JaX-FjLbaW3YQGu6WdG6ZTsi0dZO3GVMpNkG-SYu8U,33904
torchvision\models\video\resnet.py,sha256=7XjOvzBVJQQmIXCTNcaSfrvKMK56BBg3wt2uKhjLsnk,17283
torchvision\models\video\s3d.py,sha256=Rn-iypP13jrETAap1Qd4NY6kkpYDuSXjGkEKZDOxemI,8034
torchvision\models\video\swin_transformer.py,sha256=vqE3_gXMbfgaWmrxRB1pp8fh6aqnpz-djmgKhtML3c4,28418
torchvision\models\vision_transformer.py,sha256=qDIjgxi0xAapBRyriUFTjuIsTeWiQQ02nZaks7ShCoE,32988
torchvision\nvjpeg64_12.dll,sha256=3WVwgoW9qyp4LnIA0WnsxsiRZuGroL5mjztkv0uJ7C4,6171648
torchvision\ops\__init__.py,sha256=7wibGxcF1JHDviSNs9O9Pwlc8dhMSFfZo0wzVjTFnAY,2001
torchvision\ops\_box_convert.py,sha256=_Uu8BkweU4hXeaUfUEiNZ1BC-O3FPo2Ra_cu3VPOjG4,7188
torchvision\ops\_register_onnx_ops.py,sha256=g4M5Fp7n_5ZTzIQcUXvEct3YFlUMPNVSQQfBP-J0eQQ,4288
torchvision\ops\_utils.py,sha256=MxfEBDZ9tnL-QIYyDj6FEmbE6MPQZtfOljz2Yhy-Oxg,3723
torchvision\ops\boxes.py,sha256=YCbk8duaWGcm7fedGDrWJN1Sm1p_IMiTwj5Fh179VyE,20735
torchvision\ops\ciou_loss.py,sha256=EKl6TTnEFJpUlFgS3iaPuslllzxLm19G1h8B2duVx0s,2832
torchvision\ops\deform_conv.py,sha256=NyILJV9kq_nui7-rMjSCeHGATM_zZzags-6bNfBpdtc,7178
torchvision\ops\diou_loss.py,sha256=m8ML9PsaYosJHPe-8KBnj69ZoBmAcznf3V3WaEP7IfQ,3426
torchvision\ops\drop_block.py,sha256=kgQHx7tE9AoDcSBZ5NjWC4RqBKLWrBpIkVKooEWOwhQ,6248
torchvision\ops\feature_pyramid_network.py,sha256=Ojq68D4xf7I1ii6HQ1UYX6PDS5zzTuJZBNxbVUva3Uw,8933
torchvision\ops\focal_loss.py,sha256=A-Ec5GG7sbyE8ydGP6QuAPdtkUbDfdg5j4zYvs5PwzA,2480
torchvision\ops\giou_loss.py,sha256=SQ42KOFbx9pAJ-n1r9MwT3Hu5M890chnUL6oP0pLzRs,2770
torchvision\ops\misc.py,sha256=VjA5TrbwRXXZxLc0ATAZnMNH8oXZj0Gn0XO8u_2X8E0,13907
torchvision\ops\poolers.py,sha256=WPb3VxCC6fAhCCmDarUVasTkRbUQnteqZnaT9fESb9k,12228
torchvision\ops\ps_roi_align.py,sha256=6_kmnE6z_3AZZ1N2hrS_uK3cbuzqZhjdM2rC50mfYUo,3715
torchvision\ops\ps_roi_pool.py,sha256=2JrjJwzVtEeEg0BebkCnGfq4xEDwMCD-Xh915mvNcyI,2940
torchvision\ops\roi_align.py,sha256=eL--jezfuGpIjNh9FZNrL-1tjGWXHZCJ2tlN-63Vvkk,11608
torchvision\ops\roi_pool.py,sha256=kbvY49SbmfuSeKaObttS5Tbz8PztGubNpzRfHsBATM8,3009
torchvision\ops\stochastic_depth.py,sha256=9T4Zu_BaemKZafSmRwrPCVr5aaGH8tmzlsQAZO-1_-Y,2302
torchvision\prototype\__init__.py,sha256=TE6LTOe1Woda1jAUs5QZUN91JZpmpHvDSBgtEW-X2_U,53
torchvision\prototype\datasets\__init__.py,sha256=AhYIQPi2NKyYAXPNRdSUPqQgbLxXRERh52sV60UFm_A,647
torchvision\prototype\datasets\_api.py,sha256=CQT6FqmbYuWG9_zt8EySNCUsC4IX8GIlP_Ttx2-XDfk,1810
torchvision\prototype\datasets\_builtin\__init__.py,sha256=NYHJ0f09xIso6BwzIypEVzyESHPK8bn9YcaZ8Qs9CAc,690
torchvision\prototype\datasets\_builtin\caltech.py,sha256=347F0CAdnB8oyyYAFriSVvHKLoP-uwZYnqshEMn5qCw,7060
torchvision\prototype\datasets\_builtin\caltech101.categories,sha256=uC6hl4Cy3lOt_ZQhvB6FVi3G3eg5tk72ftdb8ST_Yqc,989
torchvision\prototype\datasets\_builtin\caltech256.categories,sha256=r4KdwVr7FZuvuTUSyck4kIYHVTnceEbT8iUFlxpn5dA,2878
torchvision\prototype\datasets\_builtin\celeba.py,sha256=8pJntjuk3LhlN8DNso2mu4V2iuARfdOl9JjCd6DReYg,7341
torchvision\prototype\datasets\_builtin\cifar.py,sha256=9-0nU65zAubY2bSTM7kIGk3QKJCxzwCsjj0Nf6lvEpE,4745
torchvision\prototype\datasets\_builtin\cifar10.categories,sha256=633jy9l275PzAFvCiq5iBseI102D2cYeslJqYabu72s,70
torchvision\prototype\datasets\_builtin\cifar100.categories,sha256=RDiXgAUi02RW4zCR_yqD27Q1vn9PenrG9B0mSav6GbI,825
torchvision\prototype\datasets\_builtin\clevr.py,sha256=1Q2JgqIh0F75VigoT68rLyO7K-eCrUumWC6swA3I1_g,3687
torchvision\prototype\datasets\_builtin\coco.categories,sha256=w7x2InmPfwq_K8nSTbMrOPjkpEFr_T8m5nAwhgkA390,1443
torchvision\prototype\datasets\_builtin\coco.py,sha256=zE_7kqlVEDlG8hUiS1jgsvgnLDNFck-l3xup09UShKw,10368
torchvision\prototype\datasets\_builtin\country211.categories,sha256=I8cKMrlZ_qdH8NI6_T5qkay1XkAGI_G1tui5l-_xqoE,844
torchvision\prototype\datasets\_builtin\country211.py,sha256=60pEcsi34M2URh-cV7tnxmtze_4oBEyFxllqQY5mgsc,2721
torchvision\prototype\datasets\_builtin\cub200.categories,sha256=f5qFtq_FWoFUXY6Zs9q7aBaJxvChO1hDVpWuKEB08q0,3532
torchvision\prototype\datasets\_builtin\cub200.py,sha256=wsALxF4iSv7oyTf_yFCSHfjpUpcwz_Wcnu5sN32NzNA,9576
torchvision\prototype\datasets\_builtin\dtd.categories,sha256=Q6anHvqMxN1qv05DUEkiVhxGD6-d5GPXYjkRJD2ZCLc,441
torchvision\prototype\datasets\_builtin\dtd.py,sha256=LTnQuAgWm6C157CGqf5qvJG_XIVEDeeRWXhxYhSkG-g,4764
torchvision\prototype\datasets\_builtin\eurosat.py,sha256=Kv60a3KmKMJgJFvnX7CXgDOJFEUJZvKkcP7aabGioAg,2099
torchvision\prototype\datasets\_builtin\fer2013.py,sha256=rNGgilo0l65by6nEjBVKojJzKVGBItu0QP__MPy1VtQ,2493
torchvision\prototype\datasets\_builtin\food101.categories,sha256=sUMSYDA10YVLxyghp8cDvvQvWvlM7m1x5Dl3Jyz6TKA,1285
torchvision\prototype\datasets\_builtin\food101.py,sha256=DZ0KlWIsT4WaQe94pN_WuqR_dRW9Ls06pi8Aqf1KQiw,3498
torchvision\prototype\datasets\_builtin\gtsrb.py,sha256=Rx8UaqB8fzPP9WuMQzsnwJRCVtBj46BN7ma-QYc8BDY,4152
torchvision\prototype\datasets\_builtin\imagenet.categories,sha256=teq2DhM4XaYFhDfdcmmgqG5qZvLuhFQIYZieJyUE54Y,21488
torchvision\prototype\datasets\_builtin\imagenet.py,sha256=ZrrQVrd0ioSWuLcioGXbEdaU6q74h8zeIcjbWA6mYTY,8338
torchvision\prototype\datasets\_builtin\mnist.py,sha256=GXv7rzA6XrSdvdLP6Dh3a_XMGgtBJCICn3AIU-iBv-U,15593
torchvision\prototype\datasets\_builtin\oxford-iiit-pet.categories,sha256=NCtfnYuhQPSkvUNVJKbEo7ClkpG7kiKrYxsqtf3TYU0,506
torchvision\prototype\datasets\_builtin\oxford_iiit_pet.py,sha256=pETBChDaqhzz88IIEJZtmKmLj3Jmecs0RWCf_BHvqpQ,5772
torchvision\prototype\datasets\_builtin\pcam.py,sha256=7Yjx8C4R7MI2hIMGxUIgZbNk5T7rel2hVUcFx3Rv9tI,4900
torchvision\prototype\datasets\_builtin\sbd.categories,sha256=gj_P20X71AJGFCtrBAcWXkkf3aTTmgGIPi7onwwnNOA,155
torchvision\prototype\datasets\_builtin\sbd.py,sha256=HzAt1bMzZth55LokaoT_Locrc8JCjBtRch0I4yQyePs,5798
torchvision\prototype\datasets\_builtin\semeion.py,sha256=LWYy8ikH8qa__TEsmdK6QYDLhCoNkR4zpQM4RtsMxXM,2021
torchvision\prototype\datasets\_builtin\stanford-cars.categories,sha256=ggt3mAwzYy2emjSNCStkO11zXQxoxprEOvyZxf4rYiA,5650
torchvision\prototype\datasets\_builtin\stanford_cars.py,sha256=gIHiK5hlio0qB8BP_U36A6ihKY4eyTUuSP0aLoCPkuE,4527
torchvision\prototype\datasets\_builtin\svhn.py,sha256=rD9c1jLfKX_EP361DjZOaAL1DlD4YdfSgZGcKesCeYc,2858
torchvision\prototype\datasets\_builtin\usps.py,sha256=NRr452Xx90G2KMPz5EuYIljEU_O_la-zjuaeRCxuaZc,2477
torchvision\prototype\datasets\_builtin\voc.categories,sha256=M_QJwWCMr3OOawdB-AmVUuPTaOTGTRyceSwmc8aWc8Y,171
torchvision\prototype\datasets\_builtin\voc.py,sha256=Va4biXGf-FB2dxsFHsILglicILAYY8TiS6IhE_40AjI,9527
torchvision\prototype\datasets\_folder.py,sha256=tGRiVYwooFZ_36A7jrzBpjwCIV78GU5-HwUT2Bh1Lrk,2567
torchvision\prototype\datasets\_home.py,sha256=2IZz9Q2lGeHVLRphTLp-JDRqUyiIg9IGggFl77rBTRg,676
torchvision\prototype\datasets\benchmark.py,sha256=4e5i1p0SnHmTXEcElBjLFXSND9236CnKqZCRzYkhE1U,22221
torchvision\prototype\datasets\generate_category_files.py,sha256=AcqhyQkLNoa1l0s_C-fzxaTMLADSlo7Y66ibNoUPwJA,1677
torchvision\prototype\datasets\utils\__init__.py,sha256=UWZiJQ2AZlLln6WK_Qpr7E_OQqS5XpfaBsrgpUILe5s,237
torchvision\prototype\datasets\utils\_dataset.py,sha256=qkK1D0z2DjZ2YdtQsyHSOcp-4CIi8o0q5Q34qRmkaBk,1992
torchvision\prototype\datasets\utils\_encoded.py,sha256=QA14NEpyuLPWgeby423QZF0JJzEfVQBOK8zkpX1vVqQ,1892
torchvision\prototype\datasets\utils\_internal.py,sha256=MGFTV6m3OScL1TjK689pNtXhXJNsJx6T_um_DFUh-nE,6713
torchvision\prototype\datasets\utils\_resource.py,sha256=IC4sXNRmsFJnBVymGs7_o9Wr8TDCW1DZuN-5W_8OtrA,8610
torchvision\prototype\models\__init__.py,sha256=ZcKkotg_rCpLiY1iH4yWCfgF4pVoqC1eT8oUenuXCcQ,21
torchvision\prototype\models\depth\__init__.py,sha256=Zohl1Dy0JyCwHmGz10iqljPuNmuhjGcerB3KN4HLiIw,22
torchvision\prototype\models\depth\stereo\__init__.py,sha256=FbuL-euu3pNVLmRWrwdAdDn0Cw9wPhVa6cE3bLv75oU,54
torchvision\prototype\models\depth\stereo\crestereo.py,sha256=8_587tEb-ddV5jBW27RmNaa26Yj4FdB-TzF1o4JCLvI,66077
torchvision\prototype\models\depth\stereo\raft_stereo.py,sha256=EHJ4ZHRiCyDa_zdW9kbJOOynEPK5KoQ15pgpUJYjFZ0,37994
torchvision\prototype\transforms\__init__.py,sha256=5E6bttsVC5Ihpg3JMneKCH5g16N5m0TSqVcAhXM-6dE,236
torchvision\prototype\transforms\_augment.py,sha256=aKSW1nn09Is8NFEt8mC3gRCtNQOnI8E3AzCFWVFdXrs,9142
torchvision\prototype\transforms\_geometry.py,sha256=RJDbpyg_9QOjmqLSfLNIvhCZmcvSnenU1UXWPqDM6Rs,4804
torchvision\prototype\transforms\_misc.py,sha256=DIg_rDpjEbACvE2Cp9Ln6DUk6eT2oK1lR-lF0by9ihc,2827
torchvision\prototype\transforms\_presets.py,sha256=6ybEhJY97LMeN9uFu__johmv8mDiqugn5sFf8Lt1iPI,3270
torchvision\prototype\transforms\_type_conversion.py,sha256=81iNmzljE3Z6enqQqjT1Eo43-J89RwsPTpOFfTgKf38,1016
torchvision\prototype\tv_tensors\__init__.py,sha256=gbnrMBnyVPuVBsNifDJQ2zUHfCDOQ3hzCvZA_0sRvmM,40
torchvision\prototype\tv_tensors\_label.py,sha256=52xoblVaLp84klSSn0wKRk9Ekd_jjFX7Rgut7pk3fVo,2148
torchvision\prototype\utils\__init__.py,sha256=rAgUfIBL0ZdJTgtLuS0RQA0rArO8xTaOSmav8qe_PhQ,25
torchvision\prototype\utils\_internal.py,sha256=KDOhszNNMjlScVpXapiQr-tXADmCF_hcOWXh4ZN_mp4,5435
torchvision\python312.dll,sha256=NDbUa7Zah7o9IV3wZfAQ2f2rGMmUyqJ1tUa4h3tSBbI,7470920
torchvision\transforms\__init__.py,sha256=WCNXTJUbJ1h7YaN9UfrBSvt--ST2PAV4sLICbTS-L5A,55
torchvision\transforms\_functional_pil.py,sha256=QCm2U14OXmqGsZ87B8U86yxeXMmxm3LqRzk3-_WOwyc,12514
torchvision\transforms\_functional_tensor.py,sha256=tZ2tPIT8lrnUwcFtw_6rL9ZLCbY1Lk2BXPiGEuNFTxs,34888
torchvision\transforms\_functional_video.py,sha256=c4BbUi3Y2LvskozFdy619piLBd5acsjxgogYAXmY5P8,3971
torchvision\transforms\_presets.py,sha256=iX5Lr8qZvHA-UxOAjBH-iTiu5m6l2hQRwJROsxYDs_w,8721
torchvision\transforms\_transforms_video.py,sha256=ub2gCT5ELiK918Bq-Pp6mzhWrAZxlj7blfpkA8Dhb1o,5124
torchvision\transforms\autoaugment.py,sha256=WwWSYH-q71z748AVQu9Mtf6Fo6xcmmbwsMCgS22-67M,28839
torchvision\transforms\functional.py,sha256=LKl3poyvirCF5LmBZJg2aHd-5_NgHbXl5FHEg6br-ak,69447
torchvision\transforms\transforms.py,sha256=FyXqqCpsomr0RVEHt7zi0ifmkbUAsgbj1jFeoW00mVM,88017
torchvision\transforms\v2\__init__.py,sha256=BekbfehU7c9rZ-M-bN8HExk4g6Vy0jXSBDl4b3jcxsM,1709
torchvision\transforms\v2\_augment.py,sha256=tnnle6FAHq4-xdemNBygk0PIfJDBaNOC9rUM4ir1jJo,16725
torchvision\transforms\v2\_auto_augment.py,sha256=EsuyOv_ZwIALwsNMNwJOaFg5TOl-5_oNlELbYNxObho,32868
torchvision\transforms\v2\_color.py,sha256=IcieYLHLRa4FGXEeC1fGFunMjJ0pjpmsoKo_ulVDhFo,17378
torchvision\transforms\v2\_container.py,sha256=UnxEDUeR0fwhS561bDII811tKaJ6jyxPHyXy0qdccbs,6516
torchvision\transforms\v2\_deprecated.py,sha256=EA9nX2T5it6sJiOup2BEtaEynDh6lzzSWZzTH5fcrPw,1990
torchvision\transforms\v2\_geometry.py,sha256=pJLDfRf-HuOP0mf8HN6RtNTjLshamAQZuT7EVv-RDM0,69471
torchvision\transforms\v2\_meta.py,sha256=J9s54OCuhC2aOlSfZAA9qO-xaXnjOCJtWk952ORBxYw,3246
torchvision\transforms\v2\_misc.py,sha256=WW0z0waZi80zpEh2zfU5h_yYPeGieh5OuGvcaaOoDHY,24677
torchvision\transforms\v2\_temporal.py,sha256=LnmhVdwGsRYK4jk1H_oSOSlQO5_PdbRrRPFFLDx1pO8,925
torchvision\transforms\v2\_transform.py,sha256=sjB32n5ZOn1KpyeQPJBZZZGEg4hn8AO935FHctqmqnU,9510
torchvision\transforms\v2\_type_conversion.py,sha256=w5xyvyZj91EKklhPxk6qNmqkThwljEn_-sgfe74UqFY,4273
torchvision\transforms\v2\_utils.py,sha256=LetUYsYnyWPbdqod4xZM5mXVvmYI6SkjCo8WDY2BMDc,9541
torchvision\transforms\v2\functional\__init__.py,sha256=3ajwS2uk0dPW7MKxLsQ7mU6Vjg_kHT8WOKmoMiDV44w,4088
torchvision\transforms\v2\functional\_augment.py,sha256=oFPymp04zhQpTQR3O-5XUJHDnQW6-pfwWJKoP-dpWkM,3579
torchvision\transforms\v2\functional\_color.py,sha256=hLx_h4TjXFz0dZsarb3nIAFWH6h3r3Wn1lY3rlgvh8o,31117
torchvision\transforms\v2\functional\_deprecated.py,sha256=-Aza1I4OSqpbF7skVMIJA7YA6jYDgK7A54MTsSn95oI,819
torchvision\transforms\v2\functional\_geometry.py,sha256=Jv7i_yRMV-zPYK3jtfgdkCC7S3r1ZHEwhAhpVlrZi-k,115623
torchvision\transforms\v2\functional\_meta.py,sha256=jT16zxRmzjeTg24WoqyUKXw-o6UcDouzo3Fot_4hTeY,29817
torchvision\transforms\v2\functional\_misc.py,sha256=qlykcaCtQk1I5mzLeguTAmK_EMPqVS0C5V1ism0q9MU,22425
torchvision\transforms\v2\functional\_temporal.py,sha256=tSRkkqOqUQ0QXjENF82F16El1-J0IDoFKIH-ss_cpC4,1163
torchvision\transforms\v2\functional\_type_conversion.py,sha256=GFnxb_Jmb0gdcDb-LwZjN6wui9h63RFe25HJOhfV9tQ,2619
torchvision\transforms\v2\functional\_utils.py,sha256=_5ZpwY8_gxwX2ZKQbHS4Pck99hkAAY6W57n2WioH5qg,6518
torchvision\tv_tensors\__init__.py,sha256=1kRzZyGHtOwFK0dAhJqGtSjEa5buDg_L6ygwg8EnXWQ,1837
torchvision\tv_tensors\_bounding_boxes.py,sha256=E36IiYCDJcFGiFWaWGbhDWM3j0ypuB8Yq6gdVwqDYRs,7902
torchvision\tv_tensors\_dataset_wrapper.py,sha256=pgcasnVwGiQb0mmEqPkIgycI-4AV703xbBRwUFbMo9k,25171
torchvision\tv_tensors\_image.py,sha256=yg9LaAPSwpKWx08bJtTvwhuLwYfWdGk-A0AY8kpX9hw,2016
torchvision\tv_tensors\_keypoints.py,sha256=A-CzXaDhwsswZh0zQyn9Lkk_BjSllvZLTcOK659mGOM,4686
torchvision\tv_tensors\_mask.py,sha256=H7wiK_uB9oiVQu22H1PWghyipLMmndb9pnoGIPLzqG4,1486
torchvision\tv_tensors\_torch_function_helpers.py,sha256=vr1G4egyQfRjUtDedTWRope1gP4OB1hzAjKFZGXfc2Y,2402
torchvision\tv_tensors\_tv_tensor.py,sha256=RhkzUeyCELJvcm_n4WW0HCDKNCx7zRKQVBocc-Esfhw,6354
torchvision\tv_tensors\_video.py,sha256=r5_pwyvMM5h10swXEb1NhrKXAmI2GWY4ijNhD6gn24Y,1422
torchvision\utils.py,sha256=xPx2pk2Jz4DH2E7KeZ7n2Iz-bVyqVIYLwreVRwN0B7k,35361
torchvision\version.py,sha256=KjnhHP-1cOg-92TKQhwD8v-1zj71tiVCNEpewWN4_lU,220
torchvision\zlib.dll,sha256=u15-RCxwvfotPEXJYgg17MXpgZG94rwia015mgmtMLM,101192
